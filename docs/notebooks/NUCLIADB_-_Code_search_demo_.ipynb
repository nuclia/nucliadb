{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21000294",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install nucliadb-sdk==1.2.5\n",
    "! pip install nucliadb-dataset==1.2.3\n",
    "! pip install nucliadb-models==2.0.4\n",
    "! pip install transformers\n",
    "! pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a6c04da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import requests\n",
    "from nucliadb_sdk.knowledgebox import KnowledgeBox\n",
    "from nucliadb_sdk.utils import create_knowledge_box, get_or_create\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sentence_transformers import SentenceTransformer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e307ba",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Once we've started **NucliaDB's container**\n",
    "\n",
    "``` \n",
    "docker run -it \\\n",
    "       -e LOG=INFO \\\n",
    "       -p 8080:8080 \\\n",
    "       -p 8060:8060 \\\n",
    "       -p 8040:8040 \\\n",
    "       -v nucliadb-standalone:/data \\\n",
    "       nuclia/nucliadb:latest\n",
    "```\n",
    "we'll check the connection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04920c45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = requests.get(f\"http://0.0.0.0:8080\")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b42d61",
   "metadata": {},
   "source": [
    "## Setup - creating a KB\n",
    "\n",
    "In nucliadb our data containers are called knowledge boxes.\n",
    "\n",
    "To start working, we need to create one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e6fcb07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<nucliadb_sdk.knowledgebox.KnowledgeBox at 0x1786870a0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_kb = get_or_create(\"my_code_search_kb_3\")\n",
    "my_kb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0936ab3",
   "metadata": {},
   "source": [
    "## Data preparation  - Collection\n",
    "\n",
    "Then we gather the data. \n",
    "\n",
    "In this case we use the inspect library to gather all the functions from our nucliadb_sdk module\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f397f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nucliadb_sdk\n",
    "from inspect import getmembers, isfunction, ismodule,isclass,getsource\n",
    "\n",
    "def get_all_code(target_module):\n",
    "    functions=[]\n",
    "    functions_code=[]\n",
    "    for  module_name, module in getmembers(target_module,ismodule):\n",
    "        if module_name != \"logging\":\n",
    "            functions.extend([(name,fn) for name, fn in getmembers(module, isfunction) if fn.__module__ == module.__name__])\n",
    "            for my_class_name,my_class in [(name,fn) for name, fn in getmembers(module, isclass) if fn.__module__ == module.__name__]:\n",
    "                functions.extend([(name,fn) for name, fn in getmembers(my_class, isfunction) if fn.__module__ == module.__name__ and (\"__\" not in fn.__name__)])\n",
    "    functions_code=[getsource(function) for function_name,function in functions ]\n",
    "    return functions_code\n",
    "my_functions = [i.strip() for i in get_all_code(nucliadb_sdk)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524c5be1",
   "metadata": {},
   "source": [
    "Just a quick check to see how many functions we gathered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c415967",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(my_functions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2d6144",
   "metadata": {},
   "source": [
    "## Data preparation  - Create vectors\n",
    "\n",
    "Once we have all the code, we need to calculate the vectors.\n",
    "In this case we are using:\n",
    "\n",
    "Microsoft's unixcoder-base\n",
    "\n",
    "model_t5 = SentenceTransformer(\"krlvi/sentence-t5-base-nlpl-code_search_net\")\n",
    "\n",
    "model_bert = SentenceTransformer(\"krlvi/sentence-msmarco-bert-base-dot-v5-nlpl-code_search_net\")\n",
    "\n",
    "model_distilroberta = SentenceTransformer(\"flax-sentence-embeddings/st-codesearch-distilroberta-base\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c658d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/unixcoder-base\")\n",
    "\n",
    "model = AutoModel.from_pretrained(\"microsoft/unixcoder-base\")\n",
    "\n",
    "def get_vectors_roberta_pool(tokenizer, model, code_list):\n",
    "    encoded_input = tokenizer(list(code_list),padding=True, truncation=True,max_length =1024, return_tensors=\"pt\")\n",
    "    outputs = model(**encoded_input)\n",
    "    return outputs[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651d82f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_t5 = SentenceTransformer(\"krlvi/sentence-t5-base-nlpl-code_search_net\")\n",
    "model_bert = SentenceTransformer(\"krlvi/sentence-msmarco-bert-base-dot-v5-nlpl-code_search_net\")\n",
    "model_distilroberta = SentenceTransformer(\"flax-sentence-embeddings/st-codesearch-distilroberta-base\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/unixcoder-base\")\n",
    "\n",
    "model = AutoModel.from_pretrained(\"microsoft/unixcoder-base\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85bd0161",
   "metadata": {},
   "source": [
    "## Upload our Data\n",
    "\n",
    "Now we have the data and we have created the KB (knowledgebox), so we just need to upload our resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef46a96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(my_functions)):\n",
    "    label = \"nucliadb_sdk\"\n",
    "    my_kb.upload(\n",
    "        text=my_functions[i],\n",
    "        labels=[f\"code/{label}\"],\n",
    "        vectors={\"unixcoder-meanpooling\": get_vectors_roberta_pool(tokenizer, model,[my_functions[i]]).tolist(),\n",
    "                 \"t5\": model_t5.encode([my_functions[i]])[0].tolist(),\n",
    "                 \"bert\":  model_bert.encode([my_functions[i]])[0].tolist(),\n",
    "                 \"distilroberta\":  model_distilroberta.encode([my_functions[i]])[0].tolist(),\n",
    "                 },\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5e947b",
   "metadata": {},
   "source": [
    "## Checks I \n",
    "\n",
    "We uploaded only data with one label. \n",
    "\n",
    "But we could have added more if we had code from other modules, or if we wanted to label some other code features\n",
    "\n",
    "Let's check if the numbers agree!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abdee9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_kb.get_uploaded_labels()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f1af9e",
   "metadata": {},
   "source": [
    "## Checks II\n",
    "\n",
    "We can also list all the different sets of vectors we've uploaded and their dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5e299e",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_kb.list_vectorset().vectorsets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d4c296",
   "metadata": {},
   "source": [
    "## Searches\n",
    "\n",
    "Now let's start with the most interesting part, the searches!\n",
    "\n",
    "We are going to use a small function to iterate over our search results.\n",
    "\n",
    "For legibility reasons I used a simple regex to print only the name of the function,\n",
    "but feel free to modify it if you want the whole code!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf717c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def print_results(model_name, results):\n",
    "    print(f\"\\t***{model_name.upper()} RESULTS***\")\n",
    "    for result in results:\n",
    "        print(\"Function name:\",re.findall('def ([^\\(]+)', result.text)[0], end=\" -- \")\n",
    "        #print(\"Function code:\",'%.300s' %result.text,\"\\n\\t...\")\n",
    "        #print(\"Function labels:\",\" \".join(result.labels))\n",
    "        print(\"Similarity score:\",result.score) \n",
    "    print(\"-----------\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6e0fbc",
   "metadata": {},
   "source": [
    "## Text search\n",
    "\n",
    "First we search only in the text fields\n",
    "\n",
    "We will look for `create_resource` and `create a new knowledge box`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283afa13",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = my_kb.search(text=\"create_resource\")\n",
    "print_results(\"Full text search\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33f78b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = my_kb.search(text=\"create a new knowledge box\")\n",
    "print_results(\"Full text search\", results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ad6dab",
   "metadata": {},
   "source": [
    "## Vector search\n",
    "\n",
    "Full text search has its limitations, so let's try our semantic search and compare the results from different models\n",
    "\n",
    "To perform these searches we need to encode our query and pass it to the search function with the `vector` argument.\n",
    "The results will be retrieved in order from more to less similar (based on cosine similarity).\n",
    "Note that you can define a threshold (`min_score`) so that the serach will only return results with similarity higher than a certain value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9797adca",
   "metadata": {},
   "outputs": [],
   "source": [
    "query =[\"create a new knowledge box\"]\n",
    "print(\"QUERY: \",query[0])\n",
    "results_unixcoder = my_kb.search(vector=get_vectors_roberta_pool(tokenizer, model, query).tolist(), vectorset=\"unixcoder-meanpooling\", min_score=0.3)\n",
    "print_results(\"Unicoxder\", results_unixcoder)\n",
    "\n",
    "results_t5 = my_kb.search(\n",
    "    vector=model_t5.encode(query)[0], \n",
    "    vectorset=\"t5\", \n",
    "    min_score=0.3)\n",
    "print_results(\"T5\", results_t5)\n",
    "\n",
    "\n",
    "results_roberta = my_kb.search(\n",
    "    vector=model_distilroberta.encode(query)[0], \n",
    "    vectorset=\"distilroberta\", \n",
    "    min_score=0.3)\n",
    "print_results(\"DISTILROBERTA\", results_roberta)\n",
    "\n",
    "\n",
    "results_bert = my_kb.search(\n",
    "    vector=model_bert.encode(query)[0], \n",
    "    vectorset=\"bert\", \n",
    "    min_score=0.3)\n",
    "\n",
    "print_results(\"BERT\", results_roberta)\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7d117b",
   "metadata": {},
   "outputs": [],
   "source": [
    "query =[\"Upload vectors\"]\n",
    "print(\"QUERY: \",query[0])\n",
    "results_unixcoder = my_kb.search(vector=get_vectors_roberta_pool(tokenizer, model, query).tolist(), vectorset=\"unixcoder-meanpooling\", min_score=0.3)\n",
    "print_results(\"Unicoxder\", results_unixcoder)\n",
    "\n",
    "results_t5 = my_kb.search(\n",
    "    vector=model_t5.encode(query)[0], \n",
    "    vectorset=\"t5\", \n",
    "    min_score=0.4)\n",
    "print_results(\"T5\", results_t5)\n",
    "\n",
    "\n",
    "results_roberta = my_kb.search(\n",
    "    vector=model_distilroberta.encode(query)[0].tolist(), \n",
    "    vectorset=\"distilroberta\", \n",
    "    min_score=0.4)\n",
    "print_results(\"DISTILROBERTA\", results_roberta)\n",
    "\n",
    "\n",
    "results_bert = my_kb.search(\n",
    "    vector=model_bert.encode(query)[0].tolist(), \n",
    "    vectorset=\"bert\", \n",
    "    min_score=0.4)\n",
    "\n",
    "print_results(\"BERT\", results_roberta)\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae668d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query =[\"create labels\"]\n",
    "\n",
    "print(\"QUERY: \",query[0])\n",
    "results_unixcoder = my_kb.search(vector=get_vectors_roberta_pool(tokenizer, model, query).tolist(), vectorset=\"unixcoder-meanpooling\", min_score=0.3)\n",
    "print_results(\"Unicoxder\", results_unixcoder)\n",
    "\n",
    "results_t5 = my_kb.search(\n",
    "    vector=model_t5.encode(query)[0], \n",
    "    vectorset=\"t5\", \n",
    "    min_score=0.4)\n",
    "print_results(\"T5\", results_t5)\n",
    "\n",
    "\n",
    "results_roberta = my_kb.search(\n",
    "    vector=model_distilroberta.encode(query)[0].tolist(), \n",
    "    vectorset=\"distilroberta\", \n",
    "    min_score=0.4)\n",
    "print_results(\"DISTILROBERTA\", results_roberta)\n",
    "\n",
    "\n",
    "results_bert = my_kb.search(\n",
    "    vector=model_bert.encode(query)[0].tolist(), \n",
    "    vectorset=\"bert\", \n",
    "    min_score=0.4)\n",
    "\n",
    "print_results(\"BERT\", results_roberta)\n",
    "\n",
    "  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e9b5e7",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "As we can see the models with better overall results are **T5**,**BERT**, and **DISTILROBERTA**.\n",
    "And as a curiosity, even though the **BERT** and **DISTILROBERTA** were supposed to be different, their results are exactly the same\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit ('nucliadb')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "d3eb7806dcfbf1684ad808302f34ee035a5afeb95d8bfee5075b79b842ac680f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

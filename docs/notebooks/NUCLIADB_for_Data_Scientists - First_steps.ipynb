{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff958a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install \"nucliadb-sdk<=2.42.1\"\n",
    "! pip install nucliadb-dataset\n",
    "! pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a873d328",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ciniesta/.pyenv/versions/3.9.15/envs/learning/lib/python3.9/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.14) or chardet (5.1.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n",
      "/Users/ciniesta/.pyenv/versions/3.9.15/envs/learning/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from nucliadb_sdk import KnowledgeBox,Label,create_knowledge_box, get_or_create\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac219e7",
   "metadata": {},
   "source": [
    "## Setup NucliaDB\n",
    "\n",
    "- Run **NucliaDB** image:\n",
    "```bash\n",
    "docker run -it \\\n",
    "       -e LOG=INFO \\\n",
    "       -p 8080:8080 \\\n",
    "       -p 8060:8060 \\\n",
    "       -p 8040:8040 \\\n",
    "       -v nucliadb-standalone:/data \\\n",
    "       nuclia/nucliadb:latest\n",
    "```\n",
    "- Or install with pip and run:\n",
    "\n",
    "```bash\n",
    "pip install nucliadb\n",
    "nucliadb\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1460e846",
   "metadata": {},
   "source": [
    "## Check everything's up and running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f072459",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "response = requests.get(f\"http://0.0.0.0:8080\")\n",
    "\n",
    "assert response.status_code == 200, \"Ups, it seems something is not properly installed\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee6bb4a",
   "metadata": {},
   "source": [
    "## Setup - creating a KB\n",
    "\n",
    "In nucliadb our data containers are called knowledge boxes.\n",
    "\n",
    "To start working, we need to create one:\n",
    "\n",
    "*We create it with the function get_or_create so that it won't be created again if it exists*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "05525c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_kb = get_or_create(\"my_reddit_data_kb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb8454b",
   "metadata": {},
   "source": [
    "##### Setup - preparing data & model\n",
    "\n",
    "We download our dataset and the sentence embedding model we are going to use.\n",
    "\n",
    "I set the size of the sample wo 5K but you can set it to a smaller size if you want to run the notebook faster (it takes around 15 min to load 5K) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "21b93092",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset go_emotions (/Users/ciniesta/.cache/huggingface/datasets/go_emotions/raw/0.0.0/2637cfdd4e64d30249c3ed2150fa2b9d279766bfcd6a809b9f085c61a90d776d)\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 19.29it/s]\n",
      "Loading cached shuffled indices for dataset at /Users/ciniesta/.cache/huggingface/datasets/go_emotions/raw/0.0.0/2637cfdd4e64d30249c3ed2150fa2b9d279766bfcd6a809b9f085c61a90d776d/cache-66031443094dc2fe.arrow\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"go_emotions\", \"raw\")\n",
    "\n",
    "SAMPLE_SIZE = 5000\n",
    "sample = dataset[\"train\"].shuffle(seed=19).select(range(SAMPLE_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7ed1be78",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = SentenceTransformer(\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b55ccfa",
   "metadata": {},
   "source": [
    "## Uploading data to our KB\n",
    "\n",
    "we use the upload function to index text, labels and calculated vectors for each sentence of our dataset.\n",
    "Tips:\n",
    "- We can have more than one set of vectors in our data, just add another entry to the vectors dict `vectors={\"roberta-vectors\": vectors-roberta,\"bert-vectors\": vectors-bert }`\n",
    "- If you want to avoid uploading the same data twice by mistake, just add a `key` to your upload, its an unique identifier and it will update the resources when uploading them again instead of duplicating them. `key=\"my_reddit_sample\"`\n",
    "- This can take a while! If you are in a hurry you can always select a smaller size when creating the sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c8a0f310",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorset is not created, we will create it for you\n"
     ]
    }
   ],
   "source": [
    "for row in sample:\n",
    "    label = row[\"subreddit\"]\n",
    "    my_kb.upload(\n",
    "        text=row[\"text\"],\n",
    "        labels=[f\"reddit/{label}\"],\n",
    "        vectors={\"all-MiniLM-L6-v2\": encoder.encode([row[\"text\"]])[0].tolist()},\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65021855",
   "metadata": {},
   "source": [
    "## Checks\n",
    "\n",
    "Let's explore how many entries we uploaded for each label and which vectorsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "31b12fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labelsets info : \n",
      "{'reddit': LabelSet(count=5000, labels={'rpdrcringe': 30, 'loveafterlockup': 27, '90DayFiance': 26, 'yesyesyesyesno': 26, 'DoesAnybodyElse': 25, 'ENLIGHTENEDCENTRISM': 24, 'NYYankees': 24, 'The_Mueller': 24, 'entitledparents': 24, 'teenagers': 24, 'EdmontonOilers': 23, 'Gunners': 23, 'exmormon': 23, 'gaybros': 22, 'nonononoyes': 22, 'CFB': 21, 'detroitlions': 21, 'steelers': 21, '90dayfianceuncensored': 20, 'Documentaries': 20, 'MensRights': 20, 'OkCupid': 20, 'TopMindsOfReddit': 20, 'TrollXChromosomes': 20, 'VoteBlue': 20, 'forwardsfromgrandma': 20, 'nba': 20, 'torontoraptors': 20, '4PanelCringe': 19, 'JordanPeterson': 19, 'LifeProTips': 19, 'Marriage': 19, 'SelfAwarewolves': 19, 'TheSimpsons': 19, 'breakingmom': 19, 'chicago': 19, 'confessions': 19, 'fatlogic': 19, 'minnesotavikings': 19, 'raimimemes': 19, 'texas': 19, '2meirl4meirl': 18, 'Anarchism': 18, 'AnimalsBeingJerks': 18, 'IncelTears': 18, 'Jokes': 18, 'Mavericks': 18, 'Overwatch': 18, 'SeattleWA': 18, 'TeenMomOGandTeenMom2': 18})}\n",
      "Labelset:  reddit\n",
      "Labels: rpdrcringe, loveafterlockup, 90DayFiance, yesyesyesyesno, DoesAnybodyElse, ENLIGHTENEDCENTRISM, NYYankees, The_Mueller, entitledparents, teenagers, EdmontonOilers, Gunners, exmormon, gaybros, nonononoyes, CFB, detroitlions, steelers, 90dayfianceuncensored, Documentaries, MensRights, OkCupid, TopMindsOfReddit, TrollXChromosomes, VoteBlue, forwardsfromgrandma, nba, torontoraptors, 4PanelCringe, JordanPeterson, LifeProTips, Marriage, SelfAwarewolves, TheSimpsons, breakingmom, chicago, confessions, fatlogic, minnesotavikings, raimimemes, texas, 2meirl4meirl, Anarchism, AnimalsBeingJerks, IncelTears, Jokes, Mavericks, Overwatch, SeattleWA, TeenMomOGandTeenMom2\n",
      "Tagged resources: 5000\n",
      "-----------------\n",
      "Vectorsets info : \n",
      "vectorsets={'all-MiniLM-L6-v2': VectorSet(dimension=384)}\n",
      "Vectorset:  all-MiniLM-L6-v2\n",
      "Dimension: ,  384\n"
     ]
    }
   ],
   "source": [
    "my_labels = my_kb.get_uploaded_labels()\n",
    "print(\"Labelsets info : \")\n",
    "print(my_labels)\n",
    "print(\"Labelset: \", \", \".join(my_labels.keys()))\n",
    "print(\"Labels:\",\", \".join(my_labels[\"reddit\"].labels.keys()))\n",
    "print(\"Tagged resources:\",my_labels[\"reddit\"].count)\n",
    "my_vectorsets = my_kb.list_vectorset()\n",
    "print(\"-----------------\")\n",
    "print(\"Vectorsets info : \")\n",
    "print(my_vectorsets)\n",
    "print(\"Vectorset: \", \", \".join(my_vectorsets.vectorsets.keys()))\n",
    "print(\"Dimension:\",\", \",my_kb.list_vectorset().vectorsets[\"all-MiniLM-L6-v2\"].dimension)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308d76dd",
   "metadata": {},
   "source": [
    "## Filter by label\n",
    "\n",
    "Let's explore results from one of the subreddits. \n",
    "For that we filter by label, in this case `socialanxiety`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fdaff6cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: I'd like to add spontaneously experiencing unending self-loathing because you suddenly remembered that embarrassing thing you did 3 years ago.\n",
      "Labels: ['socialanxiety']\n",
      "Text: Lol well if you see an awkward looking girl in a white car following at a safe distance, just know that’s little ole anxious me!\n",
      "Labels: ['socialanxiety']\n",
      "Text: I always worry about my facial expressions. You're not alone there.\n",
      "Labels: ['socialanxiety']\n",
      "Text: I know how you feel :( I hope you start getting more good days soon. <3\n",
      "Labels: ['socialanxiety']\n",
      "Text: Take a break then get back out there!\n",
      "Labels: ['socialanxiety']\n",
      "Text: I don't drink at all specifically because the next day is sheer terror.\n",
      "Labels: ['socialanxiety']\n",
      "Text: Reading this made me pretty damn happy. Congrats hope it works out for you two.\n",
      "Labels: ['socialanxiety']\n",
      "Text: I did the same thing in school. Thank [NAME] for the library. Are you anxious about how your brother and sister would react to that?\n",
      "Labels: ['socialanxiety']\n",
      "Text: You are not stupid, just overthinking, it will get lost in countless other posts and in the future it won't matter, good luck.\n",
      "Labels: ['socialanxiety']\n",
      "Text: [NAME] why can I relate so much.\n",
      "Labels: ['socialanxiety']\n",
      "Text: You can do it, I believe in you! \n",
      "Labels: ['socialanxiety']\n",
      "Text: okay but i need a strategy on how to deal with this\n",
      "Labels: ['socialanxiety']\n",
      "Text: yes, i know that people think of me as some strange freak because i never talk to anyone and act so awkward in social situations\n",
      "Labels: ['socialanxiety']\n",
      "Text: A tshirt. I actually bought the cutest shirt that has a nasa logo on it and it says I just need some space. I love it.\n",
      "Labels: ['socialanxiety']\n",
      "Text: I always worry about my facial expressions. You're not alone there.\n",
      "Labels: ['socialanxiety']\n",
      "Text: I did the same thing in school. Thank [NAME] for the library. Are you anxious about how your brother and sister would react to that?\n",
      "Labels: ['socialanxiety']\n",
      "Text: Well done dude! Seriously :) But keep it up, don't lose this momentum.\n",
      "Labels: ['socialanxiety']\n",
      "Text: It's hard to be good to yourself.\n",
      "Labels: ['socialanxiety']\n"
     ]
    }
   ],
   "source": [
    "results = my_kb.search(\n",
    "        filter=[Label(labelset=\"reddit\", label=\"socialanxiety\")]\n",
    "    )\n",
    "for result in results:\n",
    "    print(f\"Text: {result.text}\")\n",
    "    print(f\"Labels: {result.labels}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fda4c7",
   "metadata": {},
   "source": [
    "## Text search\n",
    "\n",
    "Now let's try the full text search or keyword search.\n",
    "\n",
    "This search returns entries that contain the word or sets of words we input.\n",
    "\n",
    "First we'll look for developer and we will output the following fields for each result:\n",
    "- Text: Text of the matched results\n",
    "- Labels:  labels associated with the result, in this case the subreddit to which it belongs\n",
    "- Score: score of the result\n",
    "- Kind of score (BM25 for keyword search, Cosine similarity for semantic search)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bbdd21d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: It's just bizarre you would criticize [NAME] on his development capabilities when he's not a developer... His specialties are centered around crypto philosophy\n",
      "Labels: ['CryptoCurrency']\n",
      "Score: 6.0321736335754395\n",
      "Score Type: BM25\n",
      "------\n"
     ]
    }
   ],
   "source": [
    "results = my_kb.search(text=\"developer\")\n",
    "for result in results:\n",
    "    print(f\"Text: {result.text}\")\n",
    "    print(f\"Labels: {result.labels}\")\n",
    "    print(f\"Score: {result.score}\")\n",
    "    print(f\"Score Type: {result.score_type}\")\n",
    "    print(\"------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94d1d00",
   "metadata": {},
   "source": [
    "Since we did not get many matches, we'll look for some more words related to technology:\n",
    "- Tech\n",
    "- Technology\n",
    "- Code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2351070d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** tech\n",
      "Text: Yay! (Tech will be improved. Eeeek.)\n",
      "Labels: ['exchristian']\n",
      "Text: How many attempts did that insane tech take to pull off?\n",
      "Labels: ['CompetitiveForHonor']\n",
      "Text: Have nobody thought of the giant tech corporation selling overpriced, inferior products to sheep customers? That's odd.\n",
      "Labels: ['rickandmorty']\n",
      "Text: Have nobody thought of the giant tech corporation selling overpriced, inferior products to sheep customers? That's odd.\n",
      "Labels: ['rickandmorty']\n",
      "\n",
      "** technology\n",
      "\n",
      "** code\n",
      "Text: And those offences are not Criminal Code offences. Criminal Code offences require it be established \"beyond a reasonable doubt\" that an accused actually committed the offence.\n",
      "Labels: ['ontario']\n",
      "Text: Because a lot of people on this thread are ignoring the pirate code and I’m trying to explain that rules are there for a reason.\n",
      "Labels: ['Seaofthieves']\n"
     ]
    }
   ],
   "source": [
    "print(\"** tech\")\n",
    "results = my_kb.search(text=\"tech\")\n",
    "for result in results:\n",
    "    print(f\"Text: {result.text}\")\n",
    "    print(f\"Labels: {result.labels}\")\n",
    "    \n",
    "print(\"\\n** technology\")\n",
    "results = my_kb.search(text=\"technology\")\n",
    "for result in results:\n",
    "    print(f\"Text: {result.text}\")\n",
    "    print(f\"Labels: {result.labels}\")\n",
    "\n",
    "print(\"\\n** code\")\n",
    "results = my_kb.search(text=\"code\")\n",
    "for result in results:\n",
    "    print(f\"Text: {result.text}\")\n",
    "    print(f\"Labels: {result.labels}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb91dcb",
   "metadata": {},
   "source": [
    "Still not interesting results so we'll move on to the semantic search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bfbbf8",
   "metadata": {},
   "source": [
    "## Vector search\n",
    "\n",
    "To get results that are related to the meaning of a word/sentence, we have our semantic search. \n",
    "\n",
    "This search will return the entries in our KB with higher cosine similarity to some given vectors.\n",
    "\n",
    "That is, the sentences that the model we use to create our vectors encodes as more similar to the one we are searching for.\n",
    "\n",
    "To perfom this search, we  convert our desired query to vectors with the same model we used and input them to the search function.\n",
    "\n",
    "We need to use the field `vector` and we can add `min_score` if we want to define a minimun cosine similarity value for our results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e15aac9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: not sure if this is a joke, but if you've ever worked at a dev studio, this adds credibility if anything\n",
      "Labels: ['StarWarsBattlefront']\n",
      "Score: 0.4388854205608368\n",
      "Key: a65d48b72e0949089af23cd9d7d39fe5\n",
      "Score Type: COSINE\n",
      "------\n",
      "Text: Yay! (Tech will be improved. Eeeek.)\n",
      "Labels: ['exchristian']\n",
      "Score: 0.364839106798172\n",
      "Key: e5f585afd5fc4ac0864db1867b2d3586\n",
      "Score Type: COSINE\n",
      "------\n",
      "Text: As a computer science student but also a lifelong [NAME], the issues surrounding Amazon in Queens have left me substantially torn. \n",
      "Labels: ['nyc']\n",
      "Score: 0.3186536133289337\n",
      "Key: 09b42b88f1944573925c926612da403a\n",
      "Score Type: COSINE\n",
      "------\n",
      "Text: It's just bizarre you would criticize [NAME] on his development capabilities when he's not a developer... His specialties are centered around crypto philosophy\n",
      "Labels: ['CryptoCurrency']\n",
      "Score: 0.3089994788169861\n",
      "Key: c2382b9403ab46e5bd216f007db7ad36\n",
      "Score Type: COSINE\n",
      "------\n",
      "Text: I can't wait for all these now unregulated projects to demonstrate why we had regulations in the first place.\n",
      "Labels: ['bestof']\n",
      "Score: 0.2871556580066681\n",
      "Key: cd63b9677775406aa5f97fa9e4908d67\n",
      "Score Type: COSINE\n",
      "------\n",
      "Text: > They are working on something new... TLWGAS. I'm not ashamed to admit that I'm too dumb to figure out what that stands for\n",
      "Labels: ['KotakuInAction']\n",
      "Score: 0.2857184112071991\n",
      "Key: b375aa7d37ac46f98b7c9886c5fe5c6e\n",
      "Score Type: COSINE\n",
      "------\n",
      "Text: Sounds like people who are making a career out of being part of the bureaucracy have come across hard times. Shucks.\n",
      "Labels: ['AdviceAnimals']\n",
      "Score: 0.27950283885002136\n",
      "Key: 7e5b0c2a4c3f4ca6b607fb4bc2bf6319\n",
      "Score Type: COSINE\n",
      "------\n",
      "Text: Stick to your arts degree, the men will keep building this province, regardless of having to fix garbage the TFWs built.\n",
      "Labels: ['alberta']\n",
      "Score: 0.2761256992816925\n",
      "Key: 680eca3baaa54c1186e15ed235acd5fe\n",
      "Score Type: COSINE\n",
      "------\n",
      "Text: Correct! Unfortunately, we're looking for a bit more computing experience than knowing what site you're on. Thanks for your interest though.\n",
      "Labels: ['Calgary']\n",
      "Score: 0.274894654750824\n",
      "Key: a034b09222694d5196c16042762732bc\n",
      "Score Type: COSINE\n",
      "------\n",
      "Text: as a guy who has the ability to repair circuit boards, oh god oh fuck this is beyond cursed\n",
      "Labels: ['mildlyinfuriating']\n",
      "Score: 0.2673933207988739\n",
      "Key: 96c7067b41ad4c1bb24e90df0892c7d0\n",
      "Score Type: COSINE\n",
      "------\n"
     ]
    }
   ],
   "source": [
    "query_vectors = encoder.encode([\"Tech, devs, programming and coding\"])[0].tolist()\n",
    "results = my_kb.search(vector = query_vectors, vectorset=\"all-MiniLM-L6-v2\", min_score=0.2)\n",
    "   \n",
    "for result in results:\n",
    "    print(f\"Text: {result.text}\")\n",
    "    print(f\"Labels: {result.labels}\")\n",
    "    print(f\"Score: {result.score}\")\n",
    "    print(f\"Key: {result.key}\")\n",
    "    print(f\"Score Type: {result.score_type}\")\n",
    "    print(\"------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "faca34a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: I’m a crybaby now, but I’m so happy to see happiness\n",
      "Labels: ['wholesomememes']\n",
      "Score: 0.5495570302009583\n",
      "Key: 1d188463e32f4fd5b4b04aaaa6487a17\n",
      "Score Type: COSINE\n",
      "------\n",
      "Text: Happy just came out\n",
      "Labels: ['netflix']\n",
      "Score: 0.5028761029243469\n",
      "Key: 99eeddb655de42a19c720d462ffa5422\n",
      "Score Type: COSINE\n",
      "------\n",
      "Text: This. Making my animals happy is one of the only things that makes me happy.\n",
      "Labels: ['antinatalism']\n",
      "Score: 0.4914007782936096\n",
      "Key: 5b57a682a4f141b0a78445c52998f19b\n",
      "Score Type: COSINE\n",
      "------\n",
      "Text: more like consistent*winner*, i hope you find a lasting happiness\n",
      "Labels: ['confessions']\n",
      "Score: 0.4771484136581421\n",
      "Key: a9129aa730a64a07816326413bf8cc46\n",
      "Score Type: COSINE\n",
      "------\n",
      "Text: Thank you. I’ve been feeling a bit better since they make people happier.\n",
      "Labels: ['SuicideWatch']\n",
      "Score: 0.4405825734138489\n",
      "Key: 100bfd15d9534d52844a8f355efff1e4\n",
      "Score Type: COSINE\n",
      "------\n",
      "Text: One of the 7 dwarfs is called happy\n",
      "Labels: ['woooosh']\n",
      "Score: 0.4348929226398468\n",
      "Key: 8417800d4274475eb891936bc18cf81c\n",
      "Score Type: COSINE\n",
      "------\n",
      "Text: Thing is, some fans will *never* be happy. There is nothing that can be done to please them. That's the problem.\n",
      "Labels: ['starwarsspeculation']\n",
      "Score: 0.42141056060791016\n",
      "Key: 3af4b7105779451aa302dd80a9631db4\n",
      "Score Type: COSINE\n",
      "------\n"
     ]
    }
   ],
   "source": [
    "query_vectors = encoder.encode([\"What is happiness\"])[0].tolist()\n",
    "results = my_kb.search(vector = query_vectors, vectorset=\"all-MiniLM-L6-v2\", min_score=0.4)\n",
    "   \n",
    "for result in results:\n",
    "    print(f\"Text: {result.text}\")\n",
    "    print(f\"Labels: {result.labels}\")\n",
    "    print(f\"Score: {result.score}\")\n",
    "    print(f\"Key: {result.key}\")\n",
    "    print(f\"Score Type: {result.score_type}\")\n",
    "    print(\"------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bd045103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: iS thIs a MeTapHor FoR LifE?\n",
      "Labels: ['woooosh']\n",
      "Score: 0.6362201571464539\n",
      "Key: d4e36eea8fa44a6893ff140aba7aeadb\n",
      "Score Type: COSINE\n",
      "------\n",
      "Text: So the key to living is to do nothing?\n",
      "Labels: ['philosophy']\n",
      "Score: 0.4603619873523712\n",
      "Key: b553a02516bd4c2d8bb817565e6d67c3\n",
      "Score Type: COSINE\n",
      "------\n",
      "Text: Why do you feel like you have to figure out what life is alone?\n",
      "Labels: ['confessions']\n",
      "Score: 0.42643851041793823\n",
      "Key: d7456dbfb34a4a05af0f56f94432c294\n",
      "Score Type: COSINE\n",
      "------\n",
      "Text: Story of my life\n",
      "Labels: ['MakingaMurderer']\n",
      "Score: 0.3753337562084198\n",
      "Key: 4f62500d80574619a55ef25359b9c938\n",
      "Score Type: COSINE\n",
      "------\n",
      "Text: Life is Strange is terrible. Absolutely zero gameplay...\n",
      "Labels: ['pcgaming']\n",
      "Score: 0.3414113521575928\n",
      "Key: 6517cdecbdd5484d872afaed9d558b21\n",
      "Score Type: COSINE\n",
      "------\n",
      "Text: A concept that doesn't map to reality other than as a metaphor.\n",
      "Labels: ['DebateAnAtheist']\n",
      "Score: 0.3300152122974396\n",
      "Key: 7037e671f8d2496e9c121b93ab26a31d\n",
      "Score Type: COSINE\n",
      "------\n"
     ]
    }
   ],
   "source": [
    "query_vectors = encoder.encode([\"The meaning of life\"])[0].tolist()\n",
    "results = my_kb.search(vector = query_vectors, vectorset=\"all-MiniLM-L6-v2\", min_score=0.33)\n",
    "   \n",
    "for result in results:\n",
    "    print(f\"Text: {result.text}\")\n",
    "    print(f\"Labels: {result.labels}\")\n",
    "    print(f\"Score: {result.score}\")\n",
    "    print(f\"Key: {result.key}\")\n",
    "    print(f\"Score Type: {result.score_type}\")\n",
    "    print(\"------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9c222404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Pure unconsitional love can also be dangerous: if the other person turns out to be an abuser you should propably stop loving them\n",
      "Labels: ['AskMen']\n",
      "Score: 0.44075626134872437\n",
      "Key: d42dec051c5e45068e2c0a8ffa1b4c6d\n",
      "Score Type: COSINE\n",
      "------\n",
      "Text: There is obviously love here. Don’t give up. Talk to each other.\n",
      "Labels: ['DeadBedrooms']\n",
      "Score: 0.39207711815834045\n",
      "Key: 4b5050731ad64445acedcadefd1ebaaa\n",
      "Score Type: COSINE\n",
      "------\n",
      "Text: Gotta love [NAME].\n",
      "Labels: ['Music']\n",
      "Score: 0.3871612548828125\n",
      "Key: d520e6c9fc334dc69b5b96b1b488e2ea\n",
      "Score Type: COSINE\n",
      "------\n",
      "Text: Peace and love, my brother!\n",
      "Labels: ['UpliftingNews']\n",
      "Score: 0.37950992584228516\n",
      "Key: 91f6c31f63e045beaad982e26d09c10a\n",
      "Score Type: COSINE\n",
      "------\n",
      "Text: No one in particular....i mean to people who believe that [NAME] and [NAME] are actually in love.\n",
      "Labels: ['freefolk']\n",
      "Score: 0.35776492953300476\n",
      "Key: 04c3534c1b2940279f392770c5495070\n",
      "Score Type: COSINE\n",
      "------\n",
      "Text: Some people on here are infatuated with his infatuation.\n",
      "Labels: ['MakingaMurderer']\n",
      "Score: 0.35318756103515625\n",
      "Key: 7737d272c2524fccab6425c9b306ee97\n",
      "Score Type: COSINE\n",
      "------\n",
      "Text: I for the life of me can’t figure out what this has to do with polyamory\n",
      "Labels: ['polyamory']\n",
      "Score: 0.3493594527244568\n",
      "Key: 5f08c2c189ba4b958d5bcbad04313be8\n",
      "Score Type: COSINE\n",
      "------\n",
      "Text: I love you [NAME], you is my only friend.\n",
      "Labels: ['bodybuilding']\n",
      "Score: 0.34717878699302673\n",
      "Key: b2628571fe8444b8ae4ba34181751a70\n",
      "Score Type: COSINE\n",
      "------\n",
      "Text: although he is best girl, he can never love :( he litterally doesn't have a heart\n",
      "Labels: ['Paladins']\n",
      "Score: 0.333243191242218\n",
      "Key: c33e517971574864bee226e8fda91517\n",
      "Score Type: COSINE\n",
      "------\n",
      "Text: Happy Together. It feels so natural.\n",
      "Labels: ['weezer']\n",
      "Score: 0.3323422372341156\n",
      "Key: 026379ec43a14cb688f1404df0807e1d\n",
      "Score Type: COSINE\n",
      "------\n"
     ]
    }
   ],
   "source": [
    "query_vectors = encoder.encode([\"What is love?\"])[0].tolist()\n",
    "results = my_kb.search(vector = query_vectors, vectorset=\"all-MiniLM-L6-v2\", min_score=0.3)\n",
    "   \n",
    "for result in results:\n",
    "    print(f\"Text: {result.text}\")\n",
    "    print(f\"Labels: {result.labels}\")\n",
    "    print(f\"Score: {result.score}\")\n",
    "    print(f\"Key: {result.key}\")\n",
    "    print(f\"Score Type: {result.score_type}\")\n",
    "    print(\"------\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
